{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa076075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 3000 supermarket transactions and saved to 'supermarket_transactions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "# Define a pool of 30 unique supermarket items\n",
    "ITEM_POOL = [\n",
    "    \"Milk\", \"Bread\", \"Eggs\", \"Cheese\", \"Butter\", \"Chicken Breast\", \"Ground Beef\", \"Apples\",\n",
    "    \"Bananas\", \"Oranges\", \"Tomatoes\", \"Potatoes\", \"Onions\", \"Carrots\", \"Lettuce\", \"Spinach\",\n",
    "    \"Yogurt\", \"Cereal\", \"Rice\", \"Pasta\", \"Coffee\", \"Tea\", \"Juice\", \"Soda\", \"Water\",\n",
    "    \"Chocolate\", \"Cookies\", \"Ice Cream\", \"Laundry Detergent\", \"Toothpaste\"\n",
    "]\n",
    "\n",
    "def simulate_transactions(num_transactions=3000, item_pool=ITEM_POOL, min_items=2, max_items=7):\n",
    "    transactions = []\n",
    "    for txn_id in range(1, num_transactions + 1):\n",
    "        num_items = random.randint(min_items, max_items)\n",
    "        items = random.sample(item_pool, num_items)\n",
    "        transactions.append({\n",
    "            \"TransactionID\": txn_id,\n",
    "            \"Items\": \", \".join(items)\n",
    "        })\n",
    "    return transactions\n",
    "\n",
    "def save_transactions_csv(transactions, filename=\"supermarket_transactions.csv\"):\n",
    "    with open(filename, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"TransactionID\", \"Items\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for txn in transactions:\n",
    "            writer.writerow(txn)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transactions = simulate_transactions()\n",
    "    save_transactions_csv(transactions)\n",
    "    print(f\"Simulated {len(transactions)} supermarket transactions and saved to 'supermarket_transactions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5701dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wangui\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support          itemsets\n",
      "22  0.160667           (Juice)\n",
      "29  0.160000      (Toothpaste)\n",
      "19  0.158000           (Pasta)\n",
      "2   0.157000            (Eggs)\n",
      "3   0.156667          (Cheese)\n",
      "17  0.154667          (Cereal)\n",
      "18  0.154333            (Rice)\n",
      "7   0.152667          (Apples)\n",
      "24  0.152000           (Water)\n",
      "5   0.151333  (Chicken Breast)\n"
     ]
    }
   ],
   "source": [
    "#Generated frequent itemsets with min_support=0.05 and saved top 10 to 'frequent_itemsets.csv'.\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "df = pd.read_csv(\"supermarket_transactions.csv\")\n",
    "df['ItemList'] = df['Items'].apply(lambda x: [item.strip() for item in x.split(\",\")])\n",
    "\n",
    "encoded_rows = []\n",
    "for items in df['ItemList']:\n",
    "    row = {item: 1 if item in items else 0 for item in ITEM_POOL}\n",
    "    encoded_rows.append(row)\n",
    "\n",
    "df_basket = pd.DataFrame(encoded_rows)\n",
    "\n",
    "frequent_itemsets = apriori(df_basket, min_support=0.05, use_colnames=True)\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "\n",
    "print(frequent_itemsets.head(10))\n",
    "frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: ', '.join(list(x)))\n",
    "frequent_itemsets.head(10).to_csv(\"frequent_itemsets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae860358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed frequent itemsets:\n",
      "    support          itemsets\n",
      "0  0.160667           (Juice)\n",
      "1  0.160000      (Toothpaste)\n",
      "2  0.158000           (Pasta)\n",
      "3  0.157000            (Eggs)\n",
      "4  0.156667          (Cheese)\n",
      "5  0.154667          (Cereal)\n",
      "6  0.154333            (Rice)\n",
      "7  0.152667          (Apples)\n",
      "8  0.152000           (Water)\n",
      "9  0.151333  (Chicken Breast)\n"
     ]
    }
   ],
   "source": [
    "# === Closed Frequent Itemsets Identification ===\n",
    "# [Student: Claire]\n",
    "# Logic: An itemset is closed if there is no proper superset among the frequent itemsets with the same support.\n",
    "\n",
    "# Load the frequent itemsets CSV\n",
    "import pandas as pd\n",
    "frequent_itemsets = pd.read_csv(\"frequent_itemsets.csv\")\n",
    "\n",
    "# Convert 'itemsets' from string to frozenset for set operations\n",
    "frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: frozenset(map(str.strip, x.split(','))))\n",
    "\n",
    "# Identify closed frequent itemsets\n",
    "all_itemsets = list(frequent_itemsets['itemsets'])\n",
    "all_supports = list(frequent_itemsets['support'])\n",
    "\n",
    "# Check if a given itemset is closed\n",
    "def is_closed(idx, itemsets, supports):\n",
    "    \"\"\"Return True if itemsets[idx] is closed among all itemsets.\"\"\"\n",
    "    current_set = itemsets[idx]\n",
    "    current_support = supports[idx]\n",
    "    for j, candidate_set in enumerate(itemsets):\n",
    "        # Check if candidate is a strict superset and has the same support\n",
    "        if idx != j and current_set < candidate_set and supports[j] == current_support:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Apply the function to each itemset in the DataFrame\n",
    "closed_flags = []\n",
    "for i in range(len(frequent_itemsets)):\n",
    "    closed_flags.append(is_closed(i, all_itemsets, all_supports))\n",
    "\n",
    "frequent_itemsets['closed'] = closed_flags\n",
    "\n",
    "# Extract and display closed frequent itemsets\n",
    "closed_itemsets = frequent_itemsets[frequent_itemsets['closed'] == True]\n",
    "\n",
    "print(\"Closed frequent itemsets:\")\n",
    "print(closed_itemsets[['support', 'itemsets']])\n",
    "\n",
    "# Save to CSV\n",
    "closed_itemsets.to_csv('closed_frequent_itemsets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
